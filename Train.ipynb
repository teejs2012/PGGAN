{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,os\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from utils.data import RandomNoiseGenerator,Data\n",
    "from utils.train_history import train_history\n",
    "from models.model import Generator, Discriminator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 512\n",
    "target_resol = 256\n",
    "first_resol = 4\n",
    "use_sigmoid = False\n",
    "train_kimg = 600\n",
    "transition_kimg = 600\n",
    "\n",
    "g_lr_max = 0.001\n",
    "d_lr_max = 0.001\n",
    "\n",
    "beta1 = 0\n",
    "beta2 = 0.99\n",
    "\n",
    "sample_freq = 100\n",
    "save_freq = 100\n",
    "report_freq = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/data/persona_cyclegan/anime/trainB'\n",
    "result_dir = 'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(train_dir)\n",
    "noise = RandomNoiseGenerator(latent_size, 'gaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (output_layer): GSelectLayer(\n",
      "    (pre): PixelNormLayer(eps = 1e-08)\n",
      "    (chain): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): ReshapeLayer()\n",
      "        (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (2): WScaleLayer(incoming = Conv2d)\n",
      "        (3): LeakyReLU(negative_slope=0.2)\n",
      "        (4): PixelNormLayer(eps = 1e-08)\n",
      "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): WScaleLayer(incoming = Conv2d)\n",
      "        (7): LeakyReLU(negative_slope=0.2)\n",
      "        (8): PixelNormLayer(eps = 1e-08)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Upsample(scale_factor=2, mode=nearest)\n",
      "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): WScaleLayer(incoming = Conv2d)\n",
      "        (3): LeakyReLU(negative_slope=0.2)\n",
      "        (4): PixelNormLayer(eps = 1e-08)\n",
      "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): WScaleLayer(incoming = Conv2d)\n",
      "        (7): LeakyReLU(negative_slope=0.2)\n",
      "        (8): PixelNormLayer(eps = 1e-08)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Upsample(scale_factor=2, mode=nearest)\n",
      "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): WScaleLayer(incoming = Conv2d)\n",
      "        (3): LeakyReLU(negative_slope=0.2)\n",
      "        (4): PixelNormLayer(eps = 1e-08)\n",
      "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): WScaleLayer(incoming = Conv2d)\n",
      "        (7): LeakyReLU(negative_slope=0.2)\n",
      "        (8): PixelNormLayer(eps = 1e-08)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Upsample(scale_factor=2, mode=nearest)\n",
      "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): WScaleLayer(incoming = Conv2d)\n",
      "        (3): LeakyReLU(negative_slope=0.2)\n",
      "        (4): PixelNormLayer(eps = 1e-08)\n",
      "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): WScaleLayer(incoming = Conv2d)\n",
      "        (7): LeakyReLU(negative_slope=0.2)\n",
      "        (8): PixelNormLayer(eps = 1e-08)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Upsample(scale_factor=2, mode=nearest)\n",
      "        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): WScaleLayer(incoming = Conv2d)\n",
      "        (3): LeakyReLU(negative_slope=0.2)\n",
      "        (4): PixelNormLayer(eps = 1e-08)\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): WScaleLayer(incoming = Conv2d)\n",
      "        (7): LeakyReLU(negative_slope=0.2)\n",
      "        (8): PixelNormLayer(eps = 1e-08)\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Upsample(scale_factor=2, mode=nearest)\n",
      "        (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): WScaleLayer(incoming = Conv2d)\n",
      "        (3): LeakyReLU(negative_slope=0.2)\n",
      "        (4): PixelNormLayer(eps = 1e-08)\n",
      "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): WScaleLayer(incoming = Conv2d)\n",
      "        (7): LeakyReLU(negative_slope=0.2)\n",
      "        (8): PixelNormLayer(eps = 1e-08)\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): Upsample(scale_factor=2, mode=nearest)\n",
      "        (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): WScaleLayer(incoming = Conv2d)\n",
      "        (3): LeakyReLU(negative_slope=0.2)\n",
      "        (4): PixelNormLayer(eps = 1e-08)\n",
      "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): WScaleLayer(incoming = Conv2d)\n",
      "        (7): LeakyReLU(negative_slope=0.2)\n",
      "        (8): PixelNormLayer(eps = 1e-08)\n",
      "      )\n",
      "    )\n",
      "    (post): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(512, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): WScaleLayer(incoming = Conv2d)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(512, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): WScaleLayer(incoming = Conv2d)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv2d(512, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): WScaleLayer(incoming = Conv2d)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(512, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): WScaleLayer(incoming = Conv2d)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): WScaleLayer(incoming = Conv2d)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Conv2d(128, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): WScaleLayer(incoming = Conv2d)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): WScaleLayer(incoming = Conv2d)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (output_layer): DSelectLayer(\n",
      "    (chain): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): GDropLayer(mode = prop, strength = 0.0, axes = [0, 1], normalize = False)\n",
      "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): WScaleLayer(incoming = Conv2d)\n",
      "        (3): LeakyReLU(negative_slope=0.2)\n",
      "        (4): GDropLayer(mode = prop, strength = 0.0, axes = [0, 1], normalize = False)\n",
      "        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): WScaleLayer(incoming = Conv2d)\n",
      "        (7): LeakyReLU(negative_slope=0.2)\n",
      "        (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): GDropLayer(mode = prop, strength = 0.0, axes = [0, 1], normalize = False)\n",
      "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): WScaleLayer(incoming = Conv2d)\n",
      "        (3): LeakyReLU(negative_slope=0.2)\n",
      "        (4): GDropLayer(mode = prop, strength = 0.0, axes = [0, 1], normalize = False)\n",
      "        (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): WScaleLayer(incoming = Conv2d)\n",
      "        (7): LeakyReLU(negative_slope=0.2)\n",
      "        (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): GDropLayer(mode = prop, strength = 0.0, axes = [0, 1], normalize = False)\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): WScaleLayer(incoming = Conv2d)\n",
      "        (3): LeakyReLU(negative_slope=0.2)\n",
      "        (4): GDropLayer(mode = prop, strength = 0.0, axes = [0, 1], normalize = False)\n",
      "        (5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): WScaleLayer(incoming = Conv2d)\n",
      "        (7): LeakyReLU(negative_slope=0.2)\n",
      "        (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): GDropLayer(mode = prop, strength = 0.0, axes = [0, 1], normalize = False)\n",
      "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): WScaleLayer(incoming = Conv2d)\n",
      "        (3): LeakyReLU(negative_slope=0.2)\n",
      "        (4): GDropLayer(mode = prop, strength = 0.0, axes = [0, 1], normalize = False)\n",
      "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): WScaleLayer(incoming = Conv2d)\n",
      "        (7): LeakyReLU(negative_slope=0.2)\n",
      "        (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): GDropLayer(mode = prop, strength = 0.0, axes = [0, 1], normalize = False)\n",
      "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): WScaleLayer(incoming = Conv2d)\n",
      "        (3): LeakyReLU(negative_slope=0.2)\n",
      "        (4): GDropLayer(mode = prop, strength = 0.0, axes = [0, 1], normalize = False)\n",
      "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): WScaleLayer(incoming = Conv2d)\n",
      "        (7): LeakyReLU(negative_slope=0.2)\n",
      "        (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): GDropLayer(mode = prop, strength = 0.0, axes = [0, 1], normalize = False)\n",
      "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (2): WScaleLayer(incoming = Conv2d)\n",
      "        (3): LeakyReLU(negative_slope=0.2)\n",
      "        (4): GDropLayer(mode = prop, strength = 0.0, axes = [0, 1], normalize = False)\n",
      "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (6): WScaleLayer(incoming = Conv2d)\n",
      "        (7): LeakyReLU(negative_slope=0.2)\n",
      "        (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): MinibatchStatConcatLayer(averaging = all)\n",
      "        (1): GDropLayer(mode = prop, strength = 0.0, axes = [0, 1], normalize = False)\n",
      "        (2): Conv2d(513, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (3): WScaleLayer(incoming = Conv2d)\n",
      "        (4): LeakyReLU(negative_slope=0.2)\n",
      "        (5): GDropLayer(mode = prop, strength = 0.0, axes = [0, 1], normalize = False)\n",
      "        (6): Conv2d(512, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "        (7): WScaleLayer(incoming = Conv2d)\n",
      "        (8): LeakyReLU(negative_slope=0.2)\n",
      "        (9): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (10): WScaleLayer(incoming = Conv2d)\n",
      "      )\n",
      "    )\n",
      "    (inputs): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): WScaleLayer(incoming = Conv2d)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(3, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): WScaleLayer(incoming = Conv2d)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv2d(3, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): WScaleLayer(incoming = Conv2d)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(3, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): WScaleLayer(incoming = Conv2d)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv2d(3, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): WScaleLayer(incoming = Conv2d)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Conv2d(3, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): WScaleLayer(incoming = Conv2d)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): Conv2d(3, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): WScaleLayer(incoming = Conv2d)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "G = Generator(num_channels=3, latent_size=latent_size, resolution=target_resol, fmap_max=latent_size, fmap_base=8192, tanh_at_end=True)\n",
    "D = Discriminator(num_channels=3, mbstat_avg='all', resolution=target_resol, fmap_max=latent_size, fmap_base=8192, sigmoid_at_end=use_sigmoid)\n",
    "print(G)\n",
    "print(D)\n",
    "G,D = G.to(device),D.to(device)\n",
    "optim_G = optim.Adam(G.parameters(), g_lr_max, betas=(beta1, beta2))\n",
    "optim_D = optim.Adam(D.parameters(), d_lr_max, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rampup_kimg = 10000\n",
    "rampdown_kimg = 10000\n",
    "total_kimg = 10000\n",
    "\n",
    "def _rampup(epoch, rampup_length):\n",
    "    if epoch < rampup_length:\n",
    "        p = max(0.0, float(epoch)) / float(rampup_length)\n",
    "        p = 1.0 - p\n",
    "        return np.exp(-p*p*5.0)\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "def _rampdown_linear(epoch, num_epochs, rampdown_length):\n",
    "    if epoch >= num_epochs - rampdown_length:\n",
    "        return float(num_epochs - epoch) / rampdown_length\n",
    "    else:\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bs(resolution):\n",
    "    R = int(np.log2(resolution))\n",
    "    if R < 7:\n",
    "        bs = 32 / 2**(max(0, R-4))\n",
    "    else:\n",
    "        bs = 8 / 2**(min(2, R-7))\n",
    "    return int(bs)\n",
    "\n",
    "bs_map = {2**R: get_bs(2**R) for R in range(2, 11)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = train_history(['G_loss','D_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "binary_op(): expected both inputs to be on same device, but input a is on cuda:0 and input b is on cuda:3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6b9c2d78680a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0moptim_D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0md_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdrop_strength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0md_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PGGAN/models/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y, cur_level, insert_y_at)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsert_y_at\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsert_y_at\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PGGAN/models/base_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y, cur_level, insert_y_at)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PGGAN/models/base_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: binary_op(): expected both inputs to be on same device, but input a is on cuda:0 and input b is on cuda:3"
     ]
    }
   ],
   "source": [
    "to_level = int(np.log2(target_resol))\n",
    "from_level = int(np.log2(first_resol))\n",
    "\n",
    "train_img = int(train_kimg * 1000)\n",
    "transition_img = int(transition_kimg * 1000)\n",
    "\n",
    "for R in range(from_level-1, to_level):\n",
    "    batch_size = bs_map[2 ** (R+1)]\n",
    "    phases = {'stabilize':[0, train_img//batch_size], 'fade_in':[train_img//batch_size+1, (transition_img+train_img)//batch_size]}\n",
    "\n",
    "    for phase in ['stabilize', 'fade_in']:\n",
    "        if phase in phases:\n",
    "            _range = phases[phase]\n",
    "            from_it = _range[0]\n",
    "            total_it = _range[1]\n",
    "            cur_nimg = _range[0]*batch_size\n",
    "            resol = 2 ** (R+1)\n",
    "            for it in range(from_it, total_it):\n",
    "                if phase == 'stabilize':\n",
    "                    cur_level = R\n",
    "                else:\n",
    "                    cur_level = R + total_it/float(from_it)\n",
    "                cur_resol = 2 ** int(np.ceil(cur_level+1))\n",
    "\n",
    "                # get a batch noise and real images\n",
    "                z = noise(batch_size)\n",
    "                real = data.next(batch_size,cur_resol,cur_level)\n",
    "\n",
    "                # ===preprocess===\n",
    "                z = Variable(torch.from_numpy(z))\n",
    "                z,real = z.to(device),real.to(device)\n",
    "                for param_group in optim_G.param_groups:\n",
    "                    lrate_coef = _rampup(cur_nimg / 1000.0, rampup_kimg)\n",
    "                    lrate_coef *= _rampdown_linear(cur_nimg / 1000.0,total_kimg, rampdown_kimg)\n",
    "                    param_group['lr'] = lrate_coef * g_lr_max\n",
    "                for param_group in optim_D.param_groups:\n",
    "                    lrate_coef = _rampup(cur_nimg / 1000.0, rampup_kimg)\n",
    "                    lrate_coef *= _rampdown_linear(cur_nimg / 1000.0, total_kimg, rampdown_kimg)\n",
    "                    param_group['lr'] = lrate_coef * d_lr_max\n",
    "\n",
    "                # ===update D===\n",
    "                optim_D.zero_grad()\n",
    "\n",
    "                fake = G(z, cur_level=cur_level)\n",
    "                d_real = D(real, cur_level=cur_level, gdrop_strength=0)\n",
    "                d_fake = D(fake.detach(), cur_level=cur_level)\n",
    "                \n",
    "#                 d_adv_loss_fake = MSE_Loss(d_fake, False) * 0.1\n",
    "#                 d_adv_loss_real = MSE_Loss(d_real, True)\n",
    "                \n",
    "                d_adv_loss_fake = torch.mean((d_fake-0)**2) * 0.1\n",
    "                d_adv_loss_real = torch.mean((d_real-1)**2)\n",
    "                \n",
    "                \n",
    "                d_loss = 0.5 * (d_adv_loss_real + d_adv_loss_fake)\n",
    "                d_loss.backward()\n",
    "                optim_D.step()\n",
    "\n",
    "                # ===update G===\n",
    "                optim_G.zero_grad()\n",
    "                d_fake = D(fake, cur_level=cur_level)\n",
    "                g_loss = torch.mean((d_fake-1)**2)\n",
    "                g_loss.backward()\n",
    "                optim_G.step()\n",
    "                \n",
    "                cur_nimg += batch_size\n",
    "                # ===report ===\n",
    "                train_hist.add_params([g_loss,d_loss])\n",
    "                if it% report_freq == 0:\n",
    "                    print('%s phase, %d resolution, %d iteration upon %d'%(phase, cur_resol, it, total_it))\n",
    "                    print(train_hist.check_current_avg())\n",
    "\n",
    "                # ===generate sample images===\n",
    "                samples = []\n",
    "                if it % sample_freq == 0:\n",
    "                    img_to_save = (fake.detach()[0].cpu().numpy().transpose(1,2,0)+1)/2\n",
    "                    plt.imsave(os.path.join(result_dir, '%dx%d-%s-%s.png' % (cur_resol, cur_resol, phase, str(it).zfill(6))), img_to_save)\n",
    "\n",
    "                # ===save model===\n",
    "                if it % save_freq == 0:\n",
    "                    g_file = os.path.join(result_dir,'G.pth')\n",
    "                    d_file = os.path.join(result_dir,'D.pth')\n",
    "                    torch.save(G.state_dict(), g_file)\n",
    "                    torch.save(D.state_dict(), d_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
