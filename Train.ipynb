{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,os\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from utils.data import RandomNoiseGenerator,Data\n",
    "from utils.train_history import train_history\n",
    "import itertools\n",
    "from models.model import Generator, Discriminator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 1024\n",
    "target_resol = 256\n",
    "first_resol = 4\n",
    "use_sigmoid = False\n",
    "train_kimg = 600\n",
    "train_img = train_kimg*1000\n",
    "transition_kimg = 600\n",
    "transition_img = transition_kimg*1000\n",
    "\n",
    "g_lr_max = 0.001\n",
    "d_lr_max = 0.001\n",
    "\n",
    "beta1 = 0\n",
    "beta2 = 0.99\n",
    "\n",
    "lambda_A=10\n",
    "lambda_B=10\n",
    "lambda_recon=0.8\n",
    "lambda_idt=0.1\n",
    "\n",
    "report_it = 400\n",
    "show_it = 400\n",
    "save_it=400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = 'results'\n",
    "if not os.path.isdir(result_dir):\n",
    "    os.makedirs(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dir = '/data/persona_cyclegan/real/trainA'\n",
    "anime_dir = '/data/persona_cyclegan/anime/trainB'\n",
    "\n",
    "data_A = Data(real_dir)\n",
    "data_B = Data(anime_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Networks initialized -------------\n",
      "G has 149458133 number of parameters\n",
      "D has 66632259 number of parameters\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "G_A = Generator(num_channels=3, latent_size=latent_size, resolution=target_resol, fmap_max=latent_size, fmap_base=8192, tanh_at_end=True)\n",
    "G_B = Generator(num_channels=3, latent_size=latent_size, resolution=target_resol, fmap_max=latent_size, fmap_base=8192, tanh_at_end=True)\n",
    "\n",
    "D_A = Discriminator(num_channels=3, mbstat_avg='all', resolution=target_resol, fmap_max=latent_size, fmap_base=8192, sigmoid_at_end=True)\n",
    "D_B = Discriminator(num_channels=3, mbstat_avg='all', resolution=target_resol, fmap_max=latent_size, fmap_base=8192, sigmoid_at_end=True)\n",
    "\n",
    "# print(G_A)\n",
    "# print(D_A)\n",
    "G_A,G_B,D_A,D_B = G_A.to(device),G_B.to(device),D_A.to(device),D_B.to(device)\n",
    "optim_G = optim.Adam(itertools.chain(G_A.parameters(),G_B.parameters()), g_lr_max, betas=(beta1, beta2))\n",
    "optim_D = optim.Adam(itertools.chain(D_A.parameters(),D_B.parameters()), d_lr_max, betas=(beta1, beta2))\n",
    "\n",
    "all_models = {'G_A.pkl':G_A,\n",
    "             'G_B.pkl':G_B,\n",
    "             'D_A.pkl':D_A,\n",
    "             'D_B.pkl':D_B}\n",
    "            \n",
    "\n",
    "print('---------- Networks initialized -------------')\n",
    "for model_name,model in [('G',G_A),('D',D_A)]:\n",
    "    num_params = 0\n",
    "    for param in model.parameters():\n",
    "        num_params += param.numel()\n",
    "    print(str.format('{} has {} number of parameters', model_name, num_params))\n",
    "print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rampup_kimg = 10000\n",
    "rampdown_kimg = 10000\n",
    "total_kimg = 10000\n",
    "\n",
    "def _rampup(epoch, rampup_length):\n",
    "    if epoch < rampup_length:\n",
    "        p = max(0.0, float(epoch)) / float(rampup_length)\n",
    "        p = 1.0 - p\n",
    "        return np.exp(-p*p*5.0)\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "def _rampdown_linear(epoch, num_epochs, rampdown_length):\n",
    "    if epoch >= num_epochs - rampdown_length:\n",
    "        return float(num_epochs - epoch) / rampdown_length\n",
    "    else:\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bs(resolution):\n",
    "    R = int(np.log2(resolution))\n",
    "    if R < 7:\n",
    "        bs = 32 / 2**(max(0, R-4))\n",
    "    else:\n",
    "        bs = 8 / 2**(min(2, R-7))\n",
    "    return int(bs)\n",
    "\n",
    "bs_map = {2**R: get_bs(2**R) for R in range(2, 11)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = train_history(['G_gan_loss',\n",
    "                                          'G_idt_loss',\n",
    "                                          'G_cycle_loss',\n",
    "                                          'D_A_loss',\n",
    "                                          'D_B_loss',                                         \n",
    "                                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_loss = nn.L1Loss().to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(models, folder):\n",
    "    for k, v in models.items():\n",
    "        torch.save(v.state_dict(), os.path.join(folder, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stabilize phase, 4 resolution, 0 iteration upon 18750\n",
      "{'G_gan_loss': tensor(2.0849), 'G_idt_loss': tensor(0.0956), 'G_cycle_loss': tensor(0.7171), 'D_A_loss': tensor(0.6170), 'D_B_loss': tensor(0.6948)}\n",
      "stabilize phase, 4 resolution, 400 iteration upon 18750\n",
      "{'G_gan_loss': tensor(0.8257), 'G_idt_loss': tensor(0.1201), 'G_cycle_loss': tensor(0.5053), 'D_A_loss': tensor(0.3082), 'D_B_loss': tensor(0.2883)}\n",
      "stabilize phase, 4 resolution, 800 iteration upon 18750\n",
      "{'G_gan_loss': tensor(0.5718), 'G_idt_loss': tensor(0.1164), 'G_cycle_loss': tensor(0.5233), 'D_A_loss': tensor(0.2590), 'D_B_loss': tensor(0.2482)}\n",
      "stabilize phase, 4 resolution, 1200 iteration upon 18750\n",
      "{'G_gan_loss': tensor(0.5669), 'G_idt_loss': tensor(0.1173), 'G_cycle_loss': tensor(0.5214), 'D_A_loss': tensor(0.2566), 'D_B_loss': tensor(0.2456)}\n"
     ]
    }
   ],
   "source": [
    "to_level = int(np.log2(target_resol))\n",
    "from_level = int(np.log2(first_resol))\n",
    "\n",
    "for R in range(from_level-1, to_level):\n",
    "    \n",
    "    batch_size = bs_map[2 ** (R+1)]\n",
    "    phases = {'stabilize':[0, train_img//batch_size], 'fade_in':[train_img//batch_size+1, (transition_img+train_img)//batch_size]}\n",
    "\n",
    "    for phase in ['stabilize', 'fade_in']:\n",
    "        if phase in phases:\n",
    "            _range = phases[phase]\n",
    "            from_it = _range[0]\n",
    "            total_it = _range[1]\n",
    "            cur_nimg = _range[0]*batch_size\n",
    "            resol = 2 ** (R+1)\n",
    "            for it in range(from_it, total_it):\n",
    "                if phase == 'stabilize':\n",
    "                    cur_level = R\n",
    "                else:\n",
    "                    cur_level = R + total_it/float(from_it)\n",
    "                cur_resol = 2 ** int(np.ceil(cur_level+1))\n",
    "\n",
    "                # get a batch noise and real images\n",
    "                real_A_cur, real_A_max = data_A.next(batch_size,cur_resol,cur_level)\n",
    "                real_A_cur, real_A_max = real_A_cur.to(device), real_A_max.to(device)\n",
    "                \n",
    "                real_B_cur, real_B_max = data_B.next(batch_size,cur_resol,cur_level)\n",
    "                real_B_cur, real_B_max = real_B_cur.to(device), real_B_max.to(device)\n",
    "                # ===preprocess===\n",
    "                for param_group in optim_G.param_groups:\n",
    "                    lrate_coef = _rampup(cur_nimg / 1000.0, rampup_kimg)\n",
    "                    lrate_coef *= _rampdown_linear(cur_nimg / 1000.0,total_kimg, rampdown_kimg)\n",
    "                    param_group['lr'] = lrate_coef * g_lr_max\n",
    "                for param_group in optim_D.param_groups:\n",
    "                    lrate_coef = _rampup(cur_nimg / 1000.0, rampup_kimg)\n",
    "                    lrate_coef *= _rampdown_linear(cur_nimg / 1000.0, total_kimg, rampdown_kimg)\n",
    "                    param_group['lr'] = lrate_coef * d_lr_max\n",
    "\n",
    "                # ===update D===\n",
    "                for model in [D_A,D_B]:\n",
    "                    for param in model.parameters():\n",
    "                        param.requires_grad = True\n",
    "                        \n",
    "                optim_D.zero_grad()\n",
    "\n",
    "                fake_B = G_A(real_A_max, cur_level=cur_level)\n",
    "                d_real_B = D_B(real_B_cur, cur_level=cur_level)\n",
    "                d_fake_B = D_B(fake_B.detach(), cur_level=cur_level)\n",
    "\n",
    "                d_real_B_loss = torch.mean((d_real_B-1)**2)\n",
    "                d_fake_B_loss = torch.mean((d_fake_B-0)**2)\n",
    "                 \n",
    "                d_loss_B = 0.5 * (d_real_B_loss + d_fake_B_loss)\n",
    "                d_loss_B.backward()\n",
    " \n",
    "                fake_A = G_B(real_B_max, cur_level=cur_level)\n",
    "                d_real_A = D_A(real_A_cur, cur_level=cur_level)\n",
    "                d_fake_A = D_A(fake_A.detach(), cur_level=cur_level)\n",
    "\n",
    "                d_real_A_loss = torch.mean((d_real_A-1)**2)\n",
    "                d_fake_A_loss = torch.mean((d_fake_A-0)**2)\n",
    "                 \n",
    "                d_loss_A = 0.5 * (d_real_A_loss + d_fake_A_loss)\n",
    "                d_loss_A.backward()\n",
    "                \n",
    "                optim_D.step()\n",
    "\n",
    "                # ===update G===\n",
    "                for model in [D_A,D_B]:\n",
    "                    for param in model.parameters():\n",
    "                        param.requires_grad = False\n",
    "                        \n",
    "                optim_G.zero_grad()\n",
    "                \n",
    "                d_fake_A = D_B(fake_B, cur_level=cur_level)\n",
    "                d_fake_A_loss = torch.mean((d_fake_A-1)**2)\n",
    "                \n",
    "                sim_A_loss = L1_loss(fake_B,real_A_cur) * lambda_idt\n",
    "                \n",
    "                recon_A = G_B(fake_B,cur_level=cur_level)\n",
    "                recon_A_loss = L1_loss(recon_A,real_A_cur) * lambda_recon\n",
    "                \n",
    "                G_A_loss = (d_fake_A_loss+sim_A_loss+recon_A_loss)*lambda_A\n",
    "                G_A_loss.backward()\n",
    "                \n",
    "                d_fake_B = D_A(fake_A,cur_level=cur_level)\n",
    "                d_fake_B_loss = torch.mean((d_fake_B-1)**2)\n",
    "                \n",
    "                sim_B_loss = L1_loss(fake_A,real_B_cur)*lambda_idt\n",
    "                \n",
    "                recon_B = G_A(fake_A,cur_level=cur_level)\n",
    "                recon_B_loss = L1_loss(recon_B,real_B_cur)*lambda_recon\n",
    "                \n",
    "                G_B_loss = (d_fake_B_loss + sim_B_loss + recon_B_loss)*lambda_B\n",
    "                G_B_loss.backward()\n",
    "                \n",
    "                G_gan_loss = d_fake_A_loss + d_fake_B_loss\n",
    "                G_idt_loss = sim_A_loss + sim_B_loss\n",
    "                G_recon_loss = recon_A_loss + recon_B_loss\n",
    "\n",
    "                optim_G.step()\n",
    "                \n",
    "                cur_nimg += batch_size\n",
    "                \n",
    "                \n",
    "                # ===report ===\n",
    "                train_hist.add_params([G_gan_loss,G_idt_loss,G_recon_loss,d_loss_A,d_loss_B])\n",
    "                if it% report_it == 0:\n",
    "                    print('%s phase, %d resolution, %d iteration upon %d'%(phase, cur_resol, it, total_it))\n",
    "                    print(train_hist.check_current_avg())\n",
    "\n",
    "                # ===generate sample images===\n",
    "                if it % show_it == 0:\n",
    "                    samples = []\n",
    "                    img_to_save = (fake_B.detach()[0].cpu().numpy().transpose(1,2,0)+1)/2\n",
    "                    plt.imsave(os.path.join(result_dir, '%dx%d-%s-%s.png' % (cur_resol, cur_resol, phase, str(it).zfill(6))), img_to_save)\n",
    "\n",
    "                # ===save model===\n",
    "                if it % save_it == 0:\n",
    "                    save_models(all_models,result_dir)\n",
    "\n",
    "    model_folder_at_scale = os.path.join(result_dir,str(R))\n",
    "    if not os.path.isdir(model_folder_at_scale):\n",
    "        os.makedirs(model_folder_at_scale)\n",
    "    save_models(all_models,model_folder_at_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
